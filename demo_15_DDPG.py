import random  # ç”¨äºéšæœºæ•°ç”Ÿæˆ
import gymnasium as gym  # Gymnasiumç¯å¢ƒåº“ï¼ˆgymçš„ç»´æŠ¤ç‰ˆæœ¬ï¼‰
import numpy as np  # æ•°å€¼è®¡ç®—åº“
from tqdm import tqdm  # è¿›åº¦æ¡æ˜¾ç¤ºåº“
import torch  # PyTorchæ·±åº¦å­¦ä¹ æ¡†æ¶
from torch import nn  # ç¥ç»ç½‘ç»œæ¨¡å—
import torch.nn.functional as F  # ç¥ç»ç½‘ç»œå‡½æ•°åº“
import matplotlib.pyplot as plt  # ç»˜å›¾åº“
import rl_utils  # è‡ªå®šä¹‰çš„å¼ºåŒ–å­¦ä¹ å·¥å…·æ¨¡å—


class PolicyNet(torch.nn.Module):
    """ç­–ç•¥ç½‘ç»œï¼ˆActorç½‘ç»œï¼‰

    ç”¨äºDDPGç®—æ³•ä¸­çš„ç­–ç•¥ç½‘ç»œï¼Œè¾“å‡ºè¿ç»­åŠ¨ä½œå€¼ã€‚
    ä½¿ç”¨tanhæ¿€æ´»å‡½æ•°ç¡®ä¿è¾“å‡ºåœ¨[-1,1]èŒƒå›´å†…ï¼Œç„¶åä¹˜ä»¥åŠ¨ä½œè¾¹ç•Œã€‚

    Args:
        state_dim: int, çŠ¶æ€ç©ºé—´ç»´åº¦
        hidden_dim: int, éšè—å±‚ç»´åº¦
        action_dim: int, åŠ¨ä½œç©ºé—´ç»´åº¦
        action_bound: float, åŠ¨ä½œçš„æœ€å¤§ç»å¯¹å€¼
    """

    def __init__(self, state_dim, hidden_dim, action_dim, action_bound):
        """åˆå§‹åŒ–ç­–ç•¥ç½‘ç»œ"""
        super(PolicyNet, self).__init__()
        # ç¬¬ä¸€ä¸ªå…¨è¿æ¥å±‚ï¼šçŠ¶æ€ç»´åº¦ -> éšè—å±‚ç»´åº¦
        self.fc1 = torch.nn.Linear(state_dim, hidden_dim)
        # ç¬¬äºŒä¸ªå…¨è¿æ¥å±‚ï¼šéšè—å±‚ç»´åº¦ -> åŠ¨ä½œç»´åº¦
        self.fc2 = torch.nn.Linear(hidden_dim, action_dim)
        # åŠ¨ä½œè¾¹ç•Œï¼Œç”¨äºå°†tanhè¾“å‡ºç¼©æ”¾åˆ°å®é™…åŠ¨ä½œèŒƒå›´
        self.action_bound = action_bound

        # æƒé‡åˆå§‹åŒ–ï¼Œæœ‰åŠ©äºGPUè®­ç»ƒç¨³å®šæ€§
        self._init_weights()

    def _init_weights(self):
        """åˆå§‹åŒ–ç½‘ç»œæƒé‡ï¼Œæé«˜GPUè®­ç»ƒç¨³å®šæ€§"""
        # ä½¿ç”¨Xavieråˆå§‹åŒ–
        torch.nn.init.xavier_uniform_(self.fc1.weight)
        torch.nn.init.xavier_uniform_(self.fc2.weight)
        # åç½®åˆå§‹åŒ–ä¸º0
        torch.nn.init.zeros_(self.fc1.bias)
        torch.nn.init.zeros_(self.fc2.bias)

    def forward(self, x):
        """å‰å‘ä¼ æ’­

        Args:
            x: torch.Tensor, è¾“å…¥çŠ¶æ€

        Returns:
            torch.Tensor, è¾“å‡ºåŠ¨ä½œï¼ŒèŒƒå›´åœ¨[-action_bound, action_bound]
        """
        # ç¬¬ä¸€å±‚ï¼šReLUæ¿€æ´»
        x = F.relu(self.fc1(x))
        # ç¬¬äºŒå±‚ï¼štanhæ¿€æ´»å¹¶ç¼©æ”¾åˆ°åŠ¨ä½œè¾¹ç•Œ
        # è¿™é‡Œé¦–å…ˆä½¿ç”¨tanhæ¿€æ´»å‡½æ•°æ˜ å°„åˆ°(-1, 1)ç„¶åå†*boundæ˜ å°„åˆ°å¯¹åº”çš„åŠ¨ä½œèŒƒå›´å†…
        return torch.tanh(self.fc2(x)) * self.action_bound


class QValueNet(torch.nn.Module):
    """Qå€¼ç½‘ç»œï¼ˆCriticç½‘ç»œï¼‰

    ç”¨äºDDPGç®—æ³•ä¸­çš„ä»·å€¼ç½‘ç»œï¼Œè¯„ä¼°çŠ¶æ€-åŠ¨ä½œå¯¹çš„Qå€¼ã€‚
    ç½‘ç»œè¾“å…¥ä¸ºçŠ¶æ€å’ŒåŠ¨ä½œçš„æ‹¼æ¥ï¼Œè¾“å‡ºå•ä¸ªQå€¼ã€‚

    Args:
        state_dim: int, çŠ¶æ€ç©ºé—´ç»´åº¦
        hidden_dim: int, éšè—å±‚ç»´åº¦
        action_dim: int, åŠ¨ä½œç©ºé—´ç»´åº¦
    """

    def __init__(self, state_dim, hidden_dim, action_dim):
        """åˆå§‹åŒ–Qå€¼ç½‘ç»œ"""
        super(QValueNet, self).__init__()
        # ç¬¬ä¸€ä¸ªå…¨è¿æ¥å±‚ï¼š(çŠ¶æ€ç»´åº¦+åŠ¨ä½œç»´åº¦) -> éšè—å±‚ç»´åº¦
        self.fc1 = torch.nn.Linear(state_dim + action_dim, hidden_dim)
        # ç¬¬äºŒä¸ªå…¨è¿æ¥å±‚ï¼šéšè—å±‚ç»´åº¦ -> éšè—å±‚ç»´åº¦
        self.fc2 = torch.nn.Linear(hidden_dim, hidden_dim)
        # è¾“å‡ºå±‚ï¼šéšè—å±‚ç»´åº¦ -> 1ï¼ˆQå€¼ï¼‰
        self.fc_out = torch.nn.Linear(hidden_dim, 1)

        # æƒé‡åˆå§‹åŒ–ï¼Œæœ‰åŠ©äºGPUè®­ç»ƒç¨³å®šæ€§
        self._init_weights()

    def _init_weights(self):
        """åˆå§‹åŒ–ç½‘ç»œæƒé‡ï¼Œæé«˜GPUè®­ç»ƒç¨³å®šæ€§"""
        # ä½¿ç”¨Xavieråˆå§‹åŒ–
        torch.nn.init.xavier_uniform_(self.fc1.weight)
        torch.nn.init.xavier_uniform_(self.fc2.weight)
        torch.nn.init.xavier_uniform_(self.fc_out.weight)
        # åç½®åˆå§‹åŒ–ä¸º0
        torch.nn.init.zeros_(self.fc1.bias)
        torch.nn.init.zeros_(self.fc2.bias)
        torch.nn.init.zeros_(self.fc_out.bias)

    def forward(self, s, a):
        """å‰å‘ä¼ æ’­

        Args:
            s: torch.Tensor, è¾“å…¥çŠ¶æ€
            a: torch.Tensor, è¾“å…¥åŠ¨ä½œ

        Returns:
            torch.Tensor, è¾“å‡ºQå€¼
        """
        # å°†çŠ¶æ€å’ŒåŠ¨ä½œåœ¨æœ€åä¸€ä¸ªç»´åº¦ä¸Šæ‹¼æ¥
        cat = torch.cat([s, a], dim=1)
        # ç¬¬ä¸€å±‚ï¼šReLUæ¿€æ´»
        x = F.relu(self.fc1(cat))
        # ç¬¬äºŒå±‚ï¼šReLUæ¿€æ´»
        x = F.relu(self.fc2(x))
        # è¾“å‡ºå±‚ï¼šç›´æ¥è¾“å‡ºQå€¼
        return self.fc_out(x)


class DDPG:
    """DDPGï¼ˆDeep Deterministic Policy Gradientï¼‰ç®—æ³•å®ç°ç±»

    DDPGæ˜¯ä¸€ç§åŸºäºActor-Criticæ¶æ„çš„æ·±åº¦å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼Œ
    ä¸“é—¨ç”¨äºè§£å†³è¿ç»­åŠ¨ä½œç©ºé—´çš„å¼ºåŒ–å­¦ä¹ é—®é¢˜ã€‚
    """

    def __init__(self, state_dim, hidden_dim, action_dim, action_bound, sigma, actor_lr, critic_lr, tau, gamma, device):
        """åˆå§‹åŒ–DDPGç®—æ³•çš„æ‰€æœ‰ç»„ä»¶

        Args:
            state_dim: int, çŠ¶æ€ç©ºé—´ç»´åº¦
            hidden_dim: int, ç¥ç»ç½‘ç»œéšè—å±‚ç»´åº¦
            action_dim: int, åŠ¨ä½œç©ºé—´ç»´åº¦
            action_bound: float, åŠ¨ä½œçš„æœ€å¤§ç»å¯¹å€¼è¾¹ç•Œ
            sigma: float, æ¢ç´¢å™ªå£°çš„æ ‡å‡†å·®
            actor_lr: float, Actorç½‘ç»œçš„å­¦ä¹ ç‡
            critic_lr: float, Criticç½‘ç»œçš„å­¦ä¹ ç‡
            tau: float, ç›®æ ‡ç½‘ç»œè½¯æ›´æ–°å‚æ•°
            gamma: float, æŠ˜æ‰£å› å­
            device: torch.device, è®¡ç®—è®¾å¤‡ï¼ˆCPUæˆ–GPUï¼‰
        """
        # åˆ›å»ºä¸»Actorç½‘ç»œï¼ˆç­–ç•¥ç½‘ç»œï¼‰å¹¶ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
        self.actor = PolicyNet(state_dim, hidden_dim, action_dim, action_bound).to(device)
        # åˆ›å»ºä¸»Criticç½‘ç»œï¼ˆä»·å€¼ç½‘ç»œï¼‰å¹¶ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
        self.critic = QValueNet(state_dim, hidden_dim, action_dim).to(device)
        # åˆ›å»ºç›®æ ‡Actorç½‘ç»œå¹¶ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
        self.target_actor = PolicyNet(state_dim, hidden_dim, action_dim, action_bound).to(device)
        # åˆ›å»ºç›®æ ‡Criticç½‘ç»œå¹¶ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
        self.target_critic = QValueNet(state_dim, hidden_dim, action_dim).to(device)

        # å°†ä¸»Criticç½‘ç»œçš„å‚æ•°å¤åˆ¶åˆ°ç›®æ ‡Criticç½‘ç»œ
        self.target_critic.load_state_dict(self.critic.state_dict())
        # å°†ä¸»Actorç½‘ç»œçš„å‚æ•°å¤åˆ¶åˆ°ç›®æ ‡Actorç½‘ç»œ
        self.target_actor.load_state_dict(self.actor.state_dict())

        # åˆ›å»ºActorç½‘ç»œçš„ä¼˜åŒ–å™¨ï¼ˆä½¿ç”¨Adamä¼˜åŒ–ç®—æ³•ï¼‰
        self.actor_optimizer = torch.optim.Adam(self.actor.parameters(), lr=actor_lr)
        # åˆ›å»ºCriticç½‘ç»œçš„ä¼˜åŒ–å™¨ï¼ˆä½¿ç”¨Adamä¼˜åŒ–ç®—æ³•ï¼‰
        self.critic_optimizer = torch.optim.Adam(self.critic.parameters(), lr=critic_lr)

        # ä¿å­˜æŠ˜æ‰£å› å­ï¼Œç”¨äºè®¡ç®—æœªæ¥å¥–åŠ±çš„ç°å€¼
        self.gamma = gamma
        # ä¿å­˜é«˜æ–¯å™ªå£°çš„æ ‡å‡†å·®ï¼Œç”¨äºåŠ¨ä½œæ¢ç´¢ï¼ˆå‡å€¼ä¸º0ï¼‰
        self.sigma = sigma
        # ä¿å­˜ç›®æ ‡ç½‘ç»œè½¯æ›´æ–°å‚æ•°ï¼Œæ§åˆ¶ç›®æ ‡ç½‘ç»œæ›´æ–°é€Ÿåº¦
        self.tau = tau
        # ä¿å­˜åŠ¨ä½œç©ºé—´ç»´åº¦
        self.action_dim = action_dim
        # ä¿å­˜åŠ¨ä½œè¾¹ç•Œå€¼
        self.action_bound = action_bound
        # ä¿å­˜è®¡ç®—è®¾å¤‡
        self.device = device

    def take_action(self, state):
        """æ ¹æ®å½“å‰çŠ¶æ€é€‰æ‹©åŠ¨ä½œï¼ˆå¸¦æ¢ç´¢å™ªå£°ï¼‰

        è¿™ä¸ªæ–¹æ³•å®ç°äº†DDPGç®—æ³•çš„åŠ¨ä½œé€‰æ‹©ç­–ç•¥ï¼ŒåŒ…æ‹¬ï¼š
        1. é€šè¿‡Actorç½‘ç»œç”Ÿæˆç¡®å®šæ€§åŠ¨ä½œ
        2. æ·»åŠ é«˜æ–¯å™ªå£°è¿›è¡Œæ¢ç´¢
        3. é™åˆ¶åŠ¨ä½œåœ¨æœ‰æ•ˆèŒƒå›´å†…

        Args:
            state: np.array, å½“å‰ç¯å¢ƒçŠ¶æ€

        Returns:
            np.array, é€‰æ‹©çš„åŠ¨ä½œï¼ˆå·²æ·»åŠ æ¢ç´¢å™ªå£°å¹¶é™åˆ¶åœ¨æœ‰æ•ˆèŒƒå›´å†…ï¼‰
        """
        # å°†numpyçŠ¶æ€æ•°ç»„è½¬æ¢ä¸ºPyTorch tensoræ ¼å¼
        # æ·»åŠ batchç»´åº¦ï¼ˆä»shape [state_dim] å˜ä¸º [1, state_dim]ï¼‰
        # ç›´æ¥åœ¨GPUè®¾å¤‡ä¸Šåˆ›å»ºtensorï¼Œé¿å…åç»­çš„è®¾å¤‡è½¬ç§»å¼€é”€
        state = torch.tensor(np.array([state]), dtype=torch.float, device=self.device)

        # ä½¿ç”¨torch.no_grad()ä¸Šä¸‹æ–‡ç®¡ç†å™¨è¿›è¡Œæ¨ç†
        # è¿™æ ·å¯ä»¥ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼ŒèŠ‚çœå†…å­˜å¹¶æé«˜æ¨ç†é€Ÿåº¦
        with torch.no_grad():
            # é€šè¿‡Actorç½‘ç»œå‰å‘ä¼ æ’­è·å–ç¡®å®šæ€§åŠ¨ä½œ
            action = self.actor(state)

        # å°†GPUä¸Šçš„tensorè½¬ç§»åˆ°CPUå¹¶è½¬æ¢ä¸ºnumpyæ•°ç»„
        # flatten()å°†shapeä»[1, action_dim]å˜ä¸º[action_dim]
        action = action.cpu().numpy().flatten()

        # æ·»åŠ é«˜æ–¯å™ªå£°è¿›è¡Œæ¢ç´¢
        # np.random.randnç”Ÿæˆæ ‡å‡†æ­£æ€åˆ†å¸ƒéšæœºæ•°ï¼Œä¹˜ä»¥sigmaè°ƒæ•´å™ªå£°å¼ºåº¦
        # åœ¨CPUä¸Šè¿›è¡Œå™ªå£°è®¡ç®—ï¼Œé¿å…GPU-CPUé¢‘ç¹æ•°æ®ä¼ è¾“
        action = action + self.sigma * np.random.randn(self.action_dim)

        # ä½¿ç”¨np.clipå°†åŠ¨ä½œé™åˆ¶åœ¨ç¯å¢ƒå…è®¸çš„èŒƒå›´å†…
        # ç¡®ä¿åŠ¨ä½œåœ¨[-action_bound, action_bound]åŒºé—´å†…
        action = np.clip(action, -self.action_bound, self.action_bound)

        # è¿”å›æœ€ç»ˆçš„åŠ¨ä½œ
        return action

    def soft_update(self, net, target_net):
        """è½¯æ›´æ–°ç›®æ ‡ç½‘ç»œå‚æ•°

        DDPGç®—æ³•ä½¿ç”¨è½¯æ›´æ–°ç­–ç•¥æ¥ç¨³å®šè®­ç»ƒè¿‡ç¨‹ã€‚ä¸ç¡¬æ›´æ–°ï¼ˆç›´æ¥å¤åˆ¶ï¼‰ä¸åŒï¼Œ
        è½¯æ›´æ–°é€šè¿‡çº¿æ€§æ’å€¼çš„æ–¹å¼é€æ¸æ›´æ–°ç›®æ ‡ç½‘ç»œå‚æ•°ï¼Œå…¬å¼ä¸ºï¼š
        Î¸_target = Ï„ * Î¸_current + (1-Ï„) * Î¸_target
        å…¶ä¸­Ï„æ˜¯ä¸€ä¸ªå¾ˆå°çš„å€¼ï¼ˆå¦‚0.005ï¼‰ï¼Œç¡®ä¿ç›®æ ‡ç½‘ç»œç¼“æ…¢è·Ÿè¸ªä¸»ç½‘ç»œã€‚

        Args:
            net: ä¸»ç½‘ç»œï¼ˆActoræˆ–Criticï¼‰
            target_net: å¯¹åº”çš„ç›®æ ‡ç½‘ç»œï¼ˆTarget Actoræˆ–Target Criticï¼‰
        """
        # ä½¿ç”¨zipå‡½æ•°åŒæ—¶éå†ç›®æ ‡ç½‘ç»œå’Œä¸»ç½‘ç»œçš„æ‰€æœ‰å‚æ•°
        # target_net.parameters()è¿”å›ç›®æ ‡ç½‘ç»œçš„æ‰€æœ‰å¯è®­ç»ƒå‚æ•°
        # net.parameters()è¿”å›ä¸»ç½‘ç»œçš„æ‰€æœ‰å¯è®­ç»ƒå‚æ•°
        for param_target, param in zip(target_net.parameters(), net.parameters()):
            # æ‰§è¡Œè½¯æ›´æ–°å…¬å¼ï¼šÎ¸_target = (1-Ï„) * Î¸_target + Ï„ * Î¸_current
            # param_target.dataè·å–ç›®æ ‡ç½‘ç»œå‚æ•°çš„æ•°æ®éƒ¨åˆ†
            # param.dataè·å–ä¸»ç½‘ç»œå‚æ•°çš„æ•°æ®éƒ¨åˆ†
            # copy_()æ–¹æ³•å°±åœ°æ›´æ–°å‚æ•°ï¼Œä¸åˆ›å»ºæ–°çš„tensor
            param_target.data.copy_(param_target.data * (1.0 - self.tau) + param.data * self.tau)

    def update(self, transition_dict):
        """æ›´æ–°DDPGç®—æ³•çš„ç½‘ç»œå‚æ•°

        è¿™æ˜¯DDPGç®—æ³•çš„æ ¸å¿ƒæ›´æ–°å‡½æ•°ï¼ŒåŒ…å«ä»¥ä¸‹æ­¥éª¤ï¼š
        1. å‡†å¤‡è®­ç»ƒæ•°æ®ï¼ˆè½¬æ¢ä¸ºGPU tensorï¼‰
        2. æ›´æ–°Criticç½‘ç»œï¼ˆæœ€å°åŒ–TDè¯¯å·®ï¼‰
        3. æ›´æ–°Actorç½‘ç»œï¼ˆæœ€å¤§åŒ–Qå€¼ï¼‰
        4. è½¯æ›´æ–°ç›®æ ‡ç½‘ç»œ

        Args:
            transition_dict: dict, åŒ…å«ç»éªŒå›æ”¾æ•°æ®çš„å­—å…¸ï¼ŒåŒ…å«ï¼š
                - 'states': å½“å‰çŠ¶æ€åˆ—è¡¨
                - 'actions': æ‰§è¡Œçš„åŠ¨ä½œåˆ—è¡¨
                - 'rewards': è·å¾—çš„å¥–åŠ±åˆ—è¡¨
                - 'next_states': ä¸‹ä¸€çŠ¶æ€åˆ—è¡¨
                - 'dones': å›åˆç»“æŸæ ‡å¿—åˆ—è¡¨
        """
        # å°†çŠ¶æ€æ•°æ®è½¬æ¢ä¸ºPyTorch tensorå¹¶ç›´æ¥åœ¨GPUä¸Šåˆ›å»º
        # å…ˆè½¬æ¢ä¸ºnumpyæ•°ç»„å†åˆ›å»ºtensorï¼Œé¿å…æ€§èƒ½è­¦å‘Š
        # dtype=torch.floatç¡®ä¿æ•°æ®ç±»å‹ä¸º32ä½æµ®ç‚¹æ•°
        # device=self.deviceç¡®ä¿tensoråœ¨æ­£ç¡®çš„è®¾å¤‡ï¼ˆGPUï¼‰ä¸Šåˆ›å»º
        states = torch.tensor(np.array(transition_dict['states']), dtype=torch.float, device=self.device)

        # å°†åŠ¨ä½œæ•°æ®è½¬æ¢ä¸ºGPU tensorå¹¶è°ƒæ•´å½¢çŠ¶
        # å…ˆè½¬æ¢ä¸ºnumpyæ•°ç»„ï¼Œç„¶ååˆ›å»ºtensorï¼Œæœ€åè°ƒæ•´å½¢çŠ¶
        # view(-1, 1)å°†ä¸€ç»´åŠ¨ä½œæ•°ç»„é‡å¡‘ä¸ºåˆ—å‘é‡å½¢çŠ¶[batch_size, 1]
        actions = torch.tensor(np.array(transition_dict['actions']), dtype=torch.float, device=self.device).view(-1, 1)

        # å°†å¥–åŠ±æ•°æ®è½¬æ¢ä¸ºGPU tensorå¹¶è°ƒæ•´å½¢çŠ¶ä¸ºåˆ—å‘é‡
        # å…ˆè½¬æ¢ä¸ºnumpyæ•°ç»„ä»¥æé«˜æ€§èƒ½
        rewards = torch.tensor(np.array(transition_dict['rewards']), dtype=torch.float, device=self.device).view(-1, 1)

        # å°†ä¸‹ä¸€çŠ¶æ€æ•°æ®è½¬æ¢ä¸ºGPU tensor
        # å…ˆè½¬æ¢ä¸ºnumpyæ•°ç»„å†åˆ›å»ºtensor
        next_states = torch.tensor(np.array(transition_dict['next_states']), dtype=torch.float, device=self.device)

        # å°†å›åˆç»“æŸæ ‡å¿—è½¬æ¢ä¸ºGPU tensorå¹¶è°ƒæ•´å½¢çŠ¶ä¸ºåˆ—å‘é‡
        # done=Trueè¡¨ç¤ºå›åˆç»“æŸï¼Œdone=Falseè¡¨ç¤ºå›åˆç»§ç»­
        # å…ˆè½¬æ¢ä¸ºnumpyæ•°ç»„ä»¥é¿å…æ€§èƒ½è­¦å‘Š
        dones = torch.tensor(np.array(transition_dict['dones']), dtype=torch.float, device=self.device).view(-1, 1)

        # ==================== æ›´æ–°Criticç½‘ç»œ ====================
        # ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨ç›®æ ‡ç½‘ç»œè®¡ç®—ä¸‹ä¸€çŠ¶æ€çš„Qå€¼
        # target_actor(next_states)ï¼šç›®æ ‡Actorç½‘ç»œæ ¹æ®ä¸‹ä¸€çŠ¶æ€ç”ŸæˆåŠ¨ä½œ
        # target_critic(next_states, ...)ï¼šç›®æ ‡Criticç½‘ç»œè¯„ä¼°(ä¸‹ä¸€çŠ¶æ€,ç›®æ ‡åŠ¨ä½œ)çš„Qå€¼
        next_q_values = self.target_critic(next_states, self.target_actor(next_states))

        # ç¬¬äºŒæ­¥ï¼šè®¡ç®—TDç›®æ ‡å€¼ï¼ˆTemporal Difference Targetï¼‰
        # å…¬å¼ï¼šQ_target = r + Î³ * Q'(s', Î¼'(s')) * (1 - done)
        # rewardsï¼šå³æ—¶å¥–åŠ±
        # self.gammaï¼šæŠ˜æ‰£å› å­ï¼Œæ§åˆ¶æœªæ¥å¥–åŠ±çš„é‡è¦æ€§
        # (1 - dones)ï¼šå¦‚æœå›åˆç»“æŸ(done=1)ï¼Œåˆ™æœªæ¥å¥–åŠ±ä¸º0
        q_targets = rewards + self.gamma * next_q_values * (1 - dones)

        # ç¬¬ä¸‰æ­¥ï¼šè®¡ç®—Criticç½‘ç»œçš„æŸå¤±å‡½æ•°
        # self.critic(states, actions)ï¼šå½“å‰Criticç½‘ç»œé¢„æµ‹çš„Qå€¼
        # F.mse_lossï¼šè®¡ç®—é¢„æµ‹Qå€¼ä¸ç›®æ ‡Qå€¼ä¹‹é—´çš„å‡æ–¹è¯¯å·®
        # torch.meanï¼šå¯¹æ‰¹æ¬¡ä¸­æ‰€æœ‰æ ·æœ¬çš„æŸå¤±å–å¹³å‡
        critic_loss = torch.mean(F.mse_loss(self.critic(states, actions), q_targets))

        # ç¬¬å››æ­¥ï¼šåå‘ä¼ æ’­æ›´æ–°Criticç½‘ç»œå‚æ•°
        self.critic_optimizer.zero_grad()  # æ¸…é›¶ä¹‹å‰ç´¯ç§¯çš„æ¢¯åº¦
        critic_loss.backward()             # è®¡ç®—æŸå¤±å‡½æ•°å…³äºå‚æ•°çš„æ¢¯åº¦
        self.critic_optimizer.step()       # ä½¿ç”¨æ¢¯åº¦æ›´æ–°Criticç½‘ç»œå‚æ•°

        # ==================== æ›´æ–°Actorç½‘ç»œ ====================
        # ç¬¬ä¸€æ­¥ï¼šè®¡ç®—Actorç½‘ç»œçš„æŸå¤±å‡½æ•°
        # self.actor(states)ï¼šActorç½‘ç»œæ ¹æ®çŠ¶æ€ç”ŸæˆåŠ¨ä½œ
        # self.critic(states, ...)ï¼šCriticç½‘ç»œè¯„ä¼°(çŠ¶æ€,ActoråŠ¨ä½œ)çš„Qå€¼
        # è´Ÿå·è¡¨ç¤ºæœ€å¤§åŒ–Qå€¼ï¼ˆæ¢¯åº¦ä¸Šå‡ï¼‰ï¼Œç­‰ä»·äºæœ€å°åŒ–-Qå€¼ï¼ˆæ¢¯åº¦ä¸‹é™ï¼‰
        actor_loss = -torch.mean(self.critic(states, self.actor(states)))

        # ç¬¬äºŒæ­¥ï¼šåå‘ä¼ æ’­æ›´æ–°Actorç½‘ç»œå‚æ•°
        self.actor_optimizer.zero_grad()   # æ¸…é›¶ä¹‹å‰ç´¯ç§¯çš„æ¢¯åº¦
        actor_loss.backward()              # è®¡ç®—æŸå¤±å‡½æ•°å…³äºå‚æ•°çš„æ¢¯åº¦
        self.actor_optimizer.step()        # ä½¿ç”¨æ¢¯åº¦æ›´æ–°Actorç½‘ç»œå‚æ•°

        # ==================== è½¯æ›´æ–°ç›®æ ‡ç½‘ç»œ ====================
        # ä½¿ç”¨è½¯æ›´æ–°ç­–ç•¥ç¼“æ…¢æ›´æ–°ç›®æ ‡ç½‘ç»œï¼Œæé«˜è®­ç»ƒç¨³å®šæ€§
        self.soft_update(self.actor, self.target_actor)    # è½¯æ›´æ–°ç›®æ ‡Actorç½‘ç»œ
        self.soft_update(self.critic, self.target_critic)  # è½¯æ›´æ–°ç›®æ ‡Criticç½‘ç»œ

# ==================== DDPGç®—æ³•è¶…å‚æ•°è®¾ç½® ====================
# Actorç½‘ç»œï¼ˆç­–ç•¥ç½‘ç»œï¼‰çš„å­¦ä¹ ç‡
# è¾ƒå°çš„å­¦ä¹ ç‡æœ‰åŠ©äºç­–ç•¥çš„ç¨³å®šå­¦ä¹ ï¼Œé¿å…ç­–ç•¥éœ‡è¡
actor_lr = 3e-4

# Criticç½‘ç»œï¼ˆä»·å€¼ç½‘ç»œï¼‰çš„å­¦ä¹ ç‡
# é€šå¸¸è®¾ç½®æ¯”Actorå­¦ä¹ ç‡å¤§ä¸€ä¸ªæ•°é‡çº§ï¼Œå› ä¸ºä»·å€¼å‡½æ•°å­¦ä¹ ç›¸å¯¹å®¹æ˜“
critic_lr = 3e-3

# æ€»çš„è®­ç»ƒå›åˆæ•°
# æ¯ä¸ªå›åˆæ™ºèƒ½ä½“ä¸ç¯å¢ƒäº¤äº’ç›´åˆ°å›åˆç»“æŸ
num_episodes = 200

# ç¥ç»ç½‘ç»œéšè—å±‚çš„ç»´åº¦ï¼ˆç¥ç»å…ƒæ•°é‡ï¼‰
# æ§åˆ¶ç½‘ç»œçš„è¡¨è¾¾èƒ½åŠ›ï¼Œè¿‡å¤§å¯èƒ½è¿‡æ‹Ÿåˆï¼Œè¿‡å°å¯èƒ½æ¬ æ‹Ÿåˆ
hidden_dim = 64

# æŠ˜æ‰£å› å­Î³ï¼Œç”¨äºè®¡ç®—æœªæ¥å¥–åŠ±çš„ç°å€¼
# æ¥è¿‘1è¡¨ç¤ºæ›´é‡è§†é•¿æœŸå¥–åŠ±ï¼Œæ¥è¿‘0è¡¨ç¤ºæ›´é‡è§†å³æ—¶å¥–åŠ±
gamma = 0.98

# ç›®æ ‡ç½‘ç»œè½¯æ›´æ–°å‚æ•°Ï„
# æ§åˆ¶ç›®æ ‡ç½‘ç»œå‘ä¸»ç½‘ç»œé è¿‘çš„é€Ÿåº¦ï¼Œè¾ƒå°å€¼ç¡®ä¿è®­ç»ƒç¨³å®š
tau = 0.005

# ç»éªŒå›æ”¾æ± çš„æœ€å¤§å®¹é‡
# å­˜å‚¨å†å²ç»éªŒç”¨äºè®­ç»ƒï¼Œæ‰“ç ´æ•°æ®ç›¸å…³æ€§
buffer_size = 10000

# å¼€å§‹è®­ç»ƒå‰å›æ”¾æ± éœ€è¦ç§¯ç´¯çš„æœ€å°æ ·æœ¬æ•°
# ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç»éªŒæ•°æ®è¿›è¡Œæœ‰æ•ˆçš„æ‰¹æ¬¡é‡‡æ ·
minimal_size = 1000

# æ¯æ¬¡è®­ç»ƒæ—¶ä»å›æ”¾æ± é‡‡æ ·çš„æ‰¹æ¬¡å¤§å°
# å½±å“è®­ç»ƒç¨³å®šæ€§å’Œè®¡ç®—æ•ˆç‡çš„å¹³è¡¡
batch_size = 64

# æ¢ç´¢å™ªå£°çš„æ ‡å‡†å·®Ïƒ
# æ·»åŠ åˆ°åŠ¨ä½œä¸Šçš„é«˜æ–¯å™ªå£°ï¼Œç”¨äºæ¢ç´¢ç¯å¢ƒ
sigma = 0.01
# ==================== è®¡ç®—è®¾å¤‡é€‰æ‹©ï¼šä¸¥æ ¼ä½¿ç”¨CUDA ====================
# æ£€æŸ¥CUDAæ˜¯å¦å¯ç”¨ï¼Œå¦‚æœä¸å¯ç”¨åˆ™æä¾›è¯¦ç»†çš„å®‰è£…æŒ‡å¯¼
if not torch.cuda.is_available():
    # æ‰“å°é”™è¯¯ä¿¡æ¯å’Œå®‰è£…æŒ‡å¯¼
    print("=" * 60)
    print("âŒ CUDAä¸å¯ç”¨ï¼")
    # æ˜¾ç¤ºå½“å‰PyTorchç‰ˆæœ¬ä¿¡æ¯
    print(f"å½“å‰PyTorchç‰ˆæœ¬: {torch.__version__}")
    print("\nè¦ä½¿ç”¨CUDAè¿›è¡Œè®­ç»ƒï¼Œè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š")

    # ç¬¬ä¸€æ­¥ï¼šæ£€æŸ¥ç¡¬ä»¶æ”¯æŒ
    print("\n1. æ£€æŸ¥æ‚¨çš„GPUæ˜¯å¦æ”¯æŒCUDAï¼š")
    print("   - è¿è¡Œ 'nvidia-smi' å‘½ä»¤æŸ¥çœ‹GPUä¿¡æ¯")

    # ç¬¬äºŒæ­¥ï¼šå®‰è£…æ”¯æŒCUDAçš„PyTorch
    print("\n2. å®‰è£…æ”¯æŒCUDAçš„PyTorchç‰ˆæœ¬ï¼š")
    print("   - è®¿é—® https://pytorch.org/get-started/locally/")
    print("   - é€‰æ‹©æ‚¨çš„CUDAç‰ˆæœ¬ï¼ˆå¦‚CUDA 11.8æˆ–12.1ï¼‰")
    print("   - è¿è¡Œç›¸åº”çš„å®‰è£…å‘½ä»¤ï¼Œä¾‹å¦‚ï¼š")
    print("     pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118")

    # ç¬¬ä¸‰æ­¥ï¼šé‡æ–°è¿è¡Œ
    print("\n3. é‡æ–°è¿è¡Œæ­¤è„šæœ¬")
    print("=" * 60)

    # æŠ›å‡ºè¿è¡Œæ—¶é”™è¯¯ï¼Œç»ˆæ­¢ç¨‹åºæ‰§è¡Œ
    raise RuntimeError("CUDAä¸å¯ç”¨ï¼è¯·æŒ‰ä¸Šè¿°æ­¥éª¤å®‰è£…æ”¯æŒCUDAçš„PyTorchç‰ˆæœ¬ã€‚")

# åˆ›å»ºCUDAè®¾å¤‡å¯¹è±¡ï¼Œæ‰€æœ‰tensorå’Œæ¨¡å‹éƒ½å°†åœ¨æ­¤è®¾å¤‡ä¸Šè¿è¡Œ
device = torch.device("cuda")

# æ˜¾ç¤ºGPUè®¾å¤‡ä¿¡æ¯ï¼Œç¡®è®¤ä½¿ç”¨çš„ç¡¬ä»¶
# get_device_name(0)è·å–ç¬¬0å·GPUçš„åç§°
print(f"âœ… ä½¿ç”¨GPUè®¾å¤‡: {torch.cuda.get_device_name(0)}")

# æ˜¾ç¤ºCUDAç‰ˆæœ¬ä¿¡æ¯
print(f"ğŸ”§ CUDAç‰ˆæœ¬: {torch.version.cuda}")

# æ˜¾ç¤ºGPUçš„æ€»å†…å­˜å®¹é‡
# get_device_properties(0).total_memoryè¿”å›å­—èŠ‚æ•°ï¼Œé™¤ä»¥1024^3è½¬æ¢ä¸ºGB
print(f"ğŸ’¾ å¯ç”¨GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")

# ==================== ç¯å¢ƒè®¾ç½®å’Œåˆå§‹åŒ– ====================
# æŒ‡å®šè¦ä½¿ç”¨çš„å¼ºåŒ–å­¦ä¹ ç¯å¢ƒåç§°
# Pendulum-v1æ˜¯ä¸€ä¸ªç»å…¸çš„è¿ç»­æ§åˆ¶ä»»åŠ¡ï¼šå€’ç«‹æ‘†å¹³è¡¡é—®é¢˜
env_name = 'Pendulum-v1'

# ä½¿ç”¨gymnasiumåº“åˆ›å»ºç¯å¢ƒå®ä¾‹
# è¿™å°†åˆå§‹åŒ–å€’ç«‹æ‘†ç¯å¢ƒï¼ŒåŒ…æ‹¬ç‰©ç†æ¨¡æ‹Ÿã€æ¸²æŸ“ç­‰åŠŸèƒ½
env = gym.make(env_name)

# ==================== è®¾ç½®éšæœºç§å­ç¡®ä¿å®éªŒå¯é‡å¤ ====================
# è®¾ç½®Pythonå†…ç½®randomæ¨¡å—çš„éšæœºç§å­
# è¿™å½±å“Pythonæ ‡å‡†åº“ä¸­çš„éšæœºæ•°ç”Ÿæˆ
random.seed(0)

# è®¾ç½®NumPyåº“çš„éšæœºç§å­
# è¿™å½±å“NumPyæ•°ç»„æ“ä½œå’Œç§‘å­¦è®¡ç®—ä¸­çš„éšæœºæ•°ç”Ÿæˆ
np.random.seed(0)

# è®¾ç½®PyTorchçš„éšæœºç§å­
# è¿™å½±å“ç¥ç»ç½‘ç»œæƒé‡åˆå§‹åŒ–ã€dropoutç­‰æ“ä½œçš„éšæœºæ€§
torch.manual_seed(0)

# æ³¨æ„ï¼šæ–°ç‰ˆæœ¬gymnasiumç¯å¢ƒä¸å†æ”¯æŒenv.seed()æ–¹æ³•
# ç¯å¢ƒçš„éšæœºæ€§ç°åœ¨é€šè¿‡å…¶ä»–æ–¹å¼æ§åˆ¶

# ==================== åˆ›å»ºç»éªŒå›æ”¾æ±  ====================
# å®ä¾‹åŒ–ç»éªŒå›æ”¾ç¼“å†²åŒºï¼Œç”¨äºå­˜å‚¨å’Œé‡‡æ ·è®­ç»ƒæ•°æ®
# buffer_sizeå‚æ•°æ§åˆ¶å›æ”¾æ± çš„æœ€å¤§å®¹é‡
replay_buffer = rl_utils.ReplayBuffer(buffer_size)

# ==================== è·å–ç¯å¢ƒä¿¡æ¯ ====================
# è·å–çŠ¶æ€ç©ºé—´çš„ç»´åº¦
# å¯¹äºå€’ç«‹æ‘†ç¯å¢ƒï¼ŒçŠ¶æ€åŒ…æ‹¬ï¼šcos(Î¸), sin(Î¸), è§’é€Ÿåº¦ï¼Œå…±3ç»´
state_dim = env.observation_space.shape[0]

# è·å–åŠ¨ä½œç©ºé—´çš„ç»´åº¦
# å¯¹äºå€’ç«‹æ‘†ç¯å¢ƒï¼ŒåŠ¨ä½œæ˜¯æ–½åŠ çš„æ‰­çŸ©ï¼Œä¸º1ç»´è¿ç»­å€¼
action_dim = env.action_space.shape[0]

# è·å–åŠ¨ä½œçš„æœ€å¤§ç»å¯¹å€¼è¾¹ç•Œ
# è¿™å®šä¹‰äº†æ™ºèƒ½ä½“å¯ä»¥è¾“å‡ºçš„åŠ¨ä½œçš„æœ‰æ•ˆèŒƒå›´
action_bound = env.action_space.high[0]

# ==================== åˆ›å»ºDDPGæ™ºèƒ½ä½“ ====================
# å®ä¾‹åŒ–DDPGç®—æ³•ï¼Œä¼ å…¥æ‰€æœ‰å¿…è¦çš„è¶…å‚æ•°
# è¿™å°†åˆ›å»ºActorç½‘ç»œã€Criticç½‘ç»œã€ç›®æ ‡ç½‘ç»œå’Œä¼˜åŒ–å™¨
agent = DDPG(state_dim, hidden_dim, action_dim, action_bound, sigma,
             actor_lr, critic_lr, tau, gamma, device)

# ==================== GPUä¼˜åŒ–è®¾ç½® ====================
# æ¸…ç†GPUæ˜¾å­˜ç¼“å­˜ï¼Œé‡Šæ”¾ä¹‹å‰å¯èƒ½å ç”¨çš„å†…å­˜
# è¿™æœ‰åŠ©äºç¡®ä¿æœ‰è¶³å¤Ÿçš„æ˜¾å­˜ç”¨äºè®­ç»ƒ
torch.cuda.empty_cache()

# å¯ç”¨cuDNNåŸºå‡†æ¨¡å¼ï¼Œè‡ªåŠ¨å¯»æ‰¾æœ€ä¼˜çš„å·ç§¯ç®—æ³•
# è™½ç„¶æœ¬ä¾‹ä¸­æ²¡æœ‰å·ç§¯å±‚ï¼Œä½†è¿™æ˜¯GPUä¼˜åŒ–çš„æ ‡å‡†åšæ³•
torch.backends.cudnn.benchmark = True

# å…è®¸éç¡®å®šæ€§æ“ä½œä»¥æé«˜GPUæ€§èƒ½
# è®¾ä¸ºFalseå¯ä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½ï¼Œä½†ä¼šç‰ºç‰²ä¸€äº›å¯é‡ç°æ€§
torch.backends.cudnn.deterministic = False

# æ˜¾ç¤ºè®­ç»ƒå¼€å§‹å‰çš„GPUå†…å­˜ä½¿ç”¨æƒ…å†µ
# memory_allocated()è¿”å›å½“å‰åˆ†é…çš„GPUå†…å­˜ï¼ˆå­—èŠ‚ï¼‰ï¼Œè½¬æ¢ä¸ºMBæ˜¾ç¤º
print(f"è®­ç»ƒå‰GPUå†…å­˜ä½¿ç”¨: {torch.cuda.memory_allocated(0) / 1024**2:.1f} MB")

# ==================== å¼€å§‹è®­ç»ƒè¿‡ç¨‹ ====================
# æ‰“å°è®­ç»ƒå¼€å§‹ä¿¡æ¯ï¼ŒåŒ…æ‹¬å…³é”®å‚æ•°
print(f"ğŸš€ å¼€å§‹è®­ç»ƒDDPGç®—æ³•...")
print(f"ğŸ¯ ç¯å¢ƒ: {env_name}")
print(f"ğŸ“Š çŠ¶æ€ç»´åº¦: {state_dim}, åŠ¨ä½œç»´åº¦: {action_dim}")
print(f"ğŸ’» è®¡ç®—è®¾å¤‡: {device}")
print(f"ğŸ“¦ æ‰¹æ¬¡å¤§å°: {batch_size}")
print(f"ğŸ”„ æ€»è®­ç»ƒå›åˆæ•°: {num_episodes}")
print("-" * 50)

# è°ƒç”¨è®­ç»ƒå‡½æ•°å¼€å§‹ç¦»çº¿ç­–ç•¥æ™ºèƒ½ä½“çš„è®­ç»ƒè¿‡ç¨‹
# è¿™å°†è¿è¡ŒæŒ‡å®šæ•°é‡çš„å›åˆï¼Œæ¯ä¸ªå›åˆåŒ…å«ç¯å¢ƒäº¤äº’å’Œç½‘ç»œæ›´æ–°
return_list = rl_utils.train_off_policy_agent(env, agent, num_episodes, replay_buffer, minimal_size, batch_size)

# ==================== è®­ç»ƒå®Œæˆåçš„ä¿¡æ¯æ˜¾ç¤º ====================
# æ‰“å°è®­ç»ƒå®Œæˆä¿¡æ¯
print(f"âœ… è®­ç»ƒå®Œæˆï¼")

# è®¡ç®—å¹¶æ˜¾ç¤ºæœ€å10ä¸ªå›åˆçš„å¹³å‡å›æŠ¥ï¼Œç”¨äºè¯„ä¼°è®­ç»ƒæ•ˆæœ
# np.mean()è®¡ç®—å¹³å‡å€¼ï¼Œ[-10:]é€‰æ‹©åˆ—è¡¨çš„æœ€å10ä¸ªå…ƒç´ 
print(f"ğŸ“ˆ æœ€å10ä¸ªå›åˆçš„å¹³å‡å›æŠ¥: {np.mean(return_list[-10:]):.3f}")

# æ˜¾ç¤ºè®­ç»ƒç»“æŸåçš„GPUå†…å­˜ä½¿ç”¨æƒ…å†µ
print(f"ğŸ’¾ è®­ç»ƒåGPUå†…å­˜ä½¿ç”¨: {torch.cuda.memory_allocated(0) / 1024**2:.1f} MB")

# æ˜¾ç¤ºè®­ç»ƒè¿‡ç¨‹ä¸­GPUå†…å­˜çš„å³°å€¼ä½¿ç”¨é‡
# max_memory_allocated()è¿”å›è‡ªç¨‹åºå¼€å§‹ä»¥æ¥çš„æœ€å¤§å†…å­˜åˆ†é…é‡
print(f"ğŸ” GPUå†…å­˜å³°å€¼ä½¿ç”¨: {torch.cuda.max_memory_allocated(0) / 1024**2:.1f} MB")

# æœ€åæ¸…ç†GPUç¼“å­˜ï¼Œé‡Šæ”¾ä¸å†éœ€è¦çš„å†…å­˜
torch.cuda.empty_cache()
print("ğŸ§¹ GPUç¼“å­˜å·²æ¸…ç†")